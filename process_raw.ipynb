{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T22:08:52.832422Z",
     "start_time": "2019-06-23T22:08:52.827565Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import requests\n",
    "import tabula as tb\n",
    "import pandas as pd\n",
    "import dask.bag as db\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T23:29:06.973539Z",
     "start_time": "2019-06-23T23:29:06.946733Z"
    }
   },
   "outputs": [],
   "source": [
    "BASE_URL = 'https://cps.edu'\n",
    "FILE_URL = ('https://cps.edu/About_CPS/Financial_information/'\n",
    "            'Pages/EmployeePositionFiles.aspx')\n",
    "\n",
    "\n",
    "def list_urls():\n",
    "    \"\"\"Get a list of urls from the file url.\"\"\"\n",
    "    request = requests.get(FILE_URL)\n",
    "    soup = BeautifulSoup(request.content, 'lxml')\n",
    "    urls = [os.path.join(BASE_URL, link.attrs['href'].lstrip('/'))\n",
    "            for link in soup.find_all('a')\n",
    "            if 'Employee' in link.attrs['href']]\n",
    "    return urls\n",
    "\n",
    "\n",
    "def get_paths(urls):\n",
    "    \"\"\"Download two files simultaneously and output to raw directory.\"\"\"\n",
    "    os.makedirs('raw', exist_ok=True)\n",
    "    db.from_sequence(urls, npartitions=2).map(\n",
    "        lambda url: os.system(f'wget -nc {url} -P raw')).compute()\n",
    "    return sorted(glob.glob(os.path.join('raw', '*.xls')) +\n",
    "                  glob.glob(os.path.join('raw', '*.pdf')))\n",
    "\n",
    "\n",
    "def parse_date(path):\n",
    "    \"\"\"Parse date into pd.Timestamp by trying three date formats.\"\"\"\n",
    "    for fmt in ['%m%d%Y', '%m_%d_%y', '%m-%d-%Y']:\n",
    "        try:\n",
    "            # right after Roster is the date\n",
    "            # :-4 to remove path extension (.xls, .pdf)\n",
    "            date_str = path.split('Roster')[-1].lstrip('_')[:-4]\n",
    "            return pd.to_datetime(date_str, format=fmt)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "\n",
    "def postprocess_df(df, date):\n",
    "    \"\"\"Make table names consistent across files.\"\"\"\n",
    "    df.columns = (df.columns\n",
    "                  .str.lower()\n",
    "                  .str.strip()\n",
    "                  .str.replace('\\n', ' ')\n",
    "                  .str.replace('\\r', ' ')\n",
    "                  .str.replace('_', ' ')\n",
    "                  )\n",
    "    df = df.rename(columns={\n",
    "        'employee name': 'name',\n",
    "        'jobcode': 'job code',\n",
    "        'job description': 'job title',\n",
    "        'department': 'unit name',\n",
    "        'pos #': 'position number',\n",
    "        'dept id': 'unit number',\n",
    "        'dept/unit name': 'unit name',\n",
    "        'gross salary': 'annual salary',\n",
    "        'fte salary': 'fte annual salary',\n",
    "        'dept/unit number': 'unit number',\n",
    "        'annual  benefit  cost': 'annual benefit cost'\n",
    "    })\n",
    "    df = df.assign(**{'date': date}).set_index('date')\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_pdf(path, date):\n",
    "    \"\"\"The PDFs' formatting change over time...\"\"\"\n",
    "    if date == pd.datetime(2012, 7, 11):\n",
    "        skiprows = 0\n",
    "        lattice = False\n",
    "    elif date > pd.datetime(2012, 7, 11):\n",
    "        skiprows = 0\n",
    "        lattice = True\n",
    "    else:\n",
    "        skiprows = 1\n",
    "        lattice = True\n",
    "\n",
    "    df = tb.read_pdf(path, pages='all', lattice=lattice,\n",
    "                     pandas_options=dict(skiprows=skiprows))\n",
    "\n",
    "    if date == pd.datetime(2012, 7, 11):\n",
    "        temp_df = df['FTE Salary'].str.split(' ', expand=True)\n",
    "        df['fte'] = temp_df[0]\n",
    "        df['annual salary'] = (\n",
    "            temp_df[1].str.lstrip('$').str.replace(',', ''))\n",
    "        df['union affiliation'] = (\n",
    "            temp_df[2]\n",
    "            .str.cat(temp_df.loc[:, 3:].astype(str), sep=' ')\n",
    "            .str.replace('None', ' ')\n",
    "        )\n",
    "        df = df.drop(columns=['FTE Salary', 'Union Affiliation'])\n",
    "\n",
    "    elif date == pd.datetime(2010, 7, 1):\n",
    "        df.columns = [\n",
    "            'position number', 'budget_category', 'unit number',\n",
    "            'unit name', 'name', 'job title', 'annual salary',\n",
    "            'fte', 'union affiliation'\n",
    "        ]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def read(path, replace=False):\n",
    "    \"\"\"Return a df from postprocessed csv, or postprocess pdf/xls.\"\"\"\n",
    "    try:\n",
    "        date = parse_date(path)\n",
    "        if date < pd.datetime(2010, 5, 2):\n",
    "            return None  # pdf tables that aren't easily readable\n",
    "\n",
    "        os.makedirs('csv', exist_ok=True)\n",
    "        csv_file = f'EmployeePositionRoster_{date:%m%d%Y}.csv'\n",
    "        csv_path = os.path.join('csv', csv_file)\n",
    "\n",
    "        if os.path.exists(csv_path) and not replace:\n",
    "            df = pd.read_csv(csv_path, index_col='date', parse_dates=True)\n",
    "        else:\n",
    "            if path.endswith('.xls'):\n",
    "                df = pd.read_excel(path)\n",
    "            elif path.endswith('.pdf'):\n",
    "                df = read_pdf(path, date)\n",
    "            df = postprocess_df(df, date)\n",
    "            df.to_csv(csv_path)\n",
    "\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(e, path)\n",
    "\n",
    "\n",
    "def clean_joined_df(df):\n",
    "    \"\"\"Perform any remaining necessary cleanups.\"\"\"\n",
    "    df.index = pd.to_datetime(df.index, errors='coerce')\n",
    "    df = df.loc[~((pd.isnull(df.index)) |\n",
    "                  (df['position number'] == 'Position Number') |\n",
    "                  (df['position number'].str.startswith('Chicago Public')) |\n",
    "                  (df['position number'].str.startswith('POSITION')) |\n",
    "                  (df['position number'].str.startswith('Position'))\n",
    "                  )]\n",
    "    df = df.loc[~pd.isnull(df['position number'])]\n",
    "    for col in ['annual salary', 'fte annual salary',\n",
    "                'total position cost', 'annual benefit cost']:\n",
    "        df.loc[:, col] = (df[col].astype(str)\n",
    "                          .str.replace(',', '')\n",
    "                          .str.replace('nan', ''))\n",
    "        if 'salary' in col:\n",
    "            df.loc[:, col] = df[col].astype(str).str.replace('$', '')\n",
    "        if 'cost' in col:\n",
    "            df.loc[:, col] = df[col].astype(str).str.replace(u'\\xa0', '')\n",
    "\n",
    "    numeric_cols = ['position number', 'unit number', 'fte', 'annual salary',\n",
    "                    'fte annual salary', 'annual benefit cost', 'job code',\n",
    "                    'total position cost']\n",
    "    text_cols = list(set(df.columns) - set(numeric_cols))\n",
    "    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric)\n",
    "    df[text_cols] = df[text_cols].astype(str).apply(\n",
    "        lambda col: col.str.replace('nan', ''))\n",
    "    df = df.sort_index()\n",
    "\n",
    "    int_cols = ['position number', 'unit number']\n",
    "    df[int_cols] = df[int_cols].astype(int)\n",
    "    df = df.drop(columns=[\n",
    "        'total position cost', 'clsindc', 'fte annual salary',\n",
    "        'budget category', 'annual benefit cost'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def load():\n",
    "    urls = list_urls()\n",
    "    paths = get_paths(urls)\n",
    "\n",
    "    pkl_file = f'EmployeePositionRoster_Joined_Cleaned.pkl'\n",
    "    if os.path.exists(pkl_file):\n",
    "        return pd.read_pickle(pkl_file)\n",
    "\n",
    "    df = pd.concat((read(path) for path in paths), sort=False)\n",
    "    df = clean_joined_df(df)\n",
    "    df.to_pickle(pkl_file)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-23T23:29:33.712272Z",
     "start_time": "2019-06-23T23:29:07.433144Z"
    }
   },
   "outputs": [],
   "source": [
    "df = load()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
